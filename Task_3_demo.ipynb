{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO76RX0spLEVkO1jQifCOSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shirshadas24/Open-Source-Models-for-Student-Competence-Analysis-Task_3_python/blob/main/Task_3_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch --quiet\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline"
      ],
      "metadata": {
        "id": "XXdoSSq5SMTR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_codebert():\n",
        "    print(\" Loading CodeBERT (microsoft/codebert-base)...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "    model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "    return tokenizer, model\n",
        "\n",
        "def load_codegen():\n",
        "    print(\" Loading CodeGen (Salesforce/codegen-350M-mono)...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
        "    return tokenizer, model\n",
        "\n",
        "codebert_tokenizer, codebert_model = load_codebert()\n",
        "codegen_tokenizer, codegen_model = load_codegen()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhpwa1a0Qvn9",
        "outputId": "f0580eb9-f699-4eae-f88f-73032a50225f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loading CodeBERT (microsoft/codebert-base)...\n",
            " Loading CodeGen (Salesforce/codegen-350M-mono)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Salesforce/codegen-350M-mono were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
            "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(code: str):\n",
        "    inputs = codebert_tokenizer(code, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = codebert_model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1)\n"
      ],
      "metadata": {
        "id": "AUnD0zpgSHdx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_continuation(code: str, max_length: int = 128):\n",
        "    inputs = codegen_tokenizer(code, return_tensors=\"pt\")\n",
        "    outputs = codegen_model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=codegen_tokenizer.eos_token_id,\n",
        "    )\n",
        "    continuation = codegen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    continuation = continuation.encode(\"ascii\", errors=\"ignore\").decode()\n",
        "    return continuation\n"
      ],
      "metadata": {
        "id": "238jcFfzSWCo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_feedback(code: str):\n",
        "    print(\"\\n===  Student Code ===\\n\")\n",
        "    print(code)\n",
        "\n",
        "    emb = get_embeddings(code)\n",
        "    print(\"\\n===  Embedding Shape (CodeBERT) ===\")\n",
        "    print(emb.shape)\n",
        "\n",
        "    continuation = generate_continuation(code)\n",
        "    print(\"\\n===  CodeGen Continuation ===\\n\")\n",
        "    print(continuation)\n",
        "\n",
        "\n",
        "    feedback = []\n",
        "    if \"while True\" in code:\n",
        "        feedback.append(\" Your loop may run forever. Consider adding a stopping condition.\")\n",
        "    if \"/\" in code and \"b\" in code:\n",
        "        feedback.append(\" Be careful with division by zero.\")\n",
        "    if \"input(\" in code:\n",
        "        feedback.append(\" Remember to handle invalid user input gracefully.\")\n",
        "\n",
        "\n",
        "    feedback.append(\" What is the purpose of this function, and does it handle all possible cases?\")\n",
        "\n",
        "    print(\"\\n===  Feedback Suggestions ===\")\n",
        "    for fb in feedback:\n",
        "        print(\"- \" + fb)"
      ],
      "metadata": {
        "id": "FgeQR1ngSYNQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "student_code = \"\"\"\n",
        "def divide(a, b):\n",
        "    while True:\n",
        "        return a / b\n",
        "\"\"\"\n",
        "\n",
        "generate_feedback(student_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZBFe_xSbWO",
        "outputId": "59d33d8e-18db-4d31-f6e3-62f3be5f0183"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===  Student Code ===\n",
            "\n",
            "\n",
            "def divide(a, b):\n",
            "    while True:\n",
            "        return a / b\n",
            "\n",
            "\n",
            "===  Embedding Shape (CodeBERT) ===\n",
            "torch.Size([1, 768])\n",
            "\n",
            "===  CodeGen Continuation ===\n",
            "\n",
            "\n",
            "def divide(a, b):\n",
            "    while True:\n",
            "        return a / b\n",
            "\n",
            "def main():\n",
            "    print(\"Divide\")\n",
            "    print(\"What is the dividend?\")\n",
            "    dividend = input()\n",
            "    print(\"What is the divisor?\")\n",
            "    divisor = input()\n",
            "    print(\"What is the result?\")\n",
            "    result = divide(int(dividend), int(divisor))\n",
            "    print(result)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n",
            "===  Feedback Suggestions ===\n",
            "-  Your loop may run forever. Consider adding a stopping condition.\n",
            "-  Be careful with division by zero.\n",
            "-  What is the purpose of this function, and does it handle all possible cases?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Test Case 2\n",
        "student_code_2 = \"\"\"\n",
        "def calculate_average(numbers):\n",
        "    total = 0\n",
        "    for i in range(len(numbers)):\n",
        "        total = numbers[i]\n",
        "    return total / len(numbers)\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n=== Student Code 2 ===\\n\")\n",
        "print(student_code_2)\n",
        "\n",
        "\n",
        "inputs_2 = codebert_tokenizer(student_code_2, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "embeddings_2 = codebert_model(**inputs_2).last_hidden_state\n",
        "print(\"\\n=== Embedding Shape (CodeBERT) ===\")\n",
        "print(embeddings_2.shape)\n",
        "\n",
        "\n",
        "inputs_cg_2 = codegen_tokenizer(student_code_2, return_tensors=\"pt\")\n",
        "outputs_cg_2 = codegen_model.generate(**inputs_cg_2, max_length=150, num_return_sequences=1)\n",
        "print(\"\\n=== CodeGen Continuation ===\\n\")\n",
        "print(codegen_tokenizer.decode(outputs_cg_2[0], skip_special_tokens=True))\n",
        "\n",
        "\n",
        "print(\"\\n=== Feedback Suggestions ===\")\n",
        "print(\"-  Model continuation (as a hint, not a solution):\")\n",
        "print(\"-  Are you sure you're updating the total correctly inside the loop?\")\n",
        "print(\"-  What happens if the input list is empty?\")\n",
        "print(\"-  Does your return value actually represent an average, or just the last element divided by the count?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_qu2BwqSd4K",
        "outputId": "449b92e1-31a9-40f3-985d-a90e08a67bbc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Student Code 2 ===\n",
            "\n",
            "\n",
            "def calculate_average(numbers):\n",
            "    total = 0\n",
            "    for i in range(len(numbers)):\n",
            "        total = numbers[i]   \n",
            "    return total / len(numbers)  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Embedding Shape (CodeBERT) ===\n",
            "torch.Size([1, 65, 768])\n",
            "\n",
            "=== CodeGen Continuation ===\n",
            "\n",
            "\n",
            "def calculate_average(numbers):\n",
            "    total = 0\n",
            "    for i in range(len(numbers)):\n",
            "        total = numbers[i]   \n",
            "    return total / len(numbers)  \n",
            "\n",
            "def main():\n",
            "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "    print(calculate_average(numbers))\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n",
            "=== Feedback Suggestions ===\n",
            "-  Model continuation (as a hint, not a solution):\n",
            "-  Are you sure you're updating the total correctly inside the loop?\n",
            "-  What happens if the input list is empty?\n",
            "-  Does your return value actually represent an average, or just the last element divided by the count?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def detect_gaps(student_code: str):\n",
        "    suggestions = []\n",
        "\n",
        "    if \"while\" in student_code and \"break\" not in student_code and \"return\" not in student_code:\n",
        "        suggestions.append(\" Your loop may run forever. Do you have a stopping condition?\")\n",
        "\n",
        "    if re.search(r\"/\\s*len\\(\", student_code):\n",
        "        suggestions.append(\" What happens if the list is empty? Division by zero might occur.\")\n",
        "\n",
        "    if \"while\" in student_code and re.search(r\"\\w+\\s*=\\s*\\w+\\s*[\\+\\-]\", student_code) is None:\n",
        "        suggestions.append(\" Are you updating your loop variable correctly inside the loop?\")\n",
        "\n",
        "    if \"total\" in student_code and \"total\" in re.findall(r\"return\\s+(.*)\", student_code):\n",
        "        if not re.search(r\"total\\s*=\\s*total\\s*[\\+\\-]\", student_code):\n",
        "            suggestions.append(\" Does your return value represent an accumulated result, or just the initial/last value?\")\n",
        "\n",
        "    if \"def \" not in student_code:\n",
        "        suggestions.append(\" Try wrapping your logic in a function for clarity and reusability.\")\n",
        "\n",
        "    if not suggestions:\n",
        "        suggestions.append(\" No obvious conceptual gaps detected. Looks good!\")\n",
        "\n",
        "    return suggestions\n"
      ],
      "metadata": {
        "id": "yheXHUH3bbUi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    print(\"\\nPaste your Python code (type END to quit):\")\n",
        "    lines = []\n",
        "    while True:\n",
        "        line = input()\n",
        "        if line.strip().upper() == \"END\":\n",
        "            break\n",
        "        lines.append(line)\n",
        "    if not lines:\n",
        "        break\n",
        "\n",
        "    student_code = \"\\n\".join(lines)\n",
        "    print(\"\\n=== Your Code ===\")\n",
        "    print(student_code)\n",
        "\n",
        "    inputs = codebert_tokenizer(student_code, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    embeddings = codebert_model(**inputs).last_hidden_state\n",
        "    print(\"\\n=== Embedding Shape (CodeBERT) ===\")\n",
        "    print(embeddings.shape)\n",
        "\n",
        "    inputs_cg = codegen_tokenizer(student_code, return_tensors=\"pt\")\n",
        "    outputs_cg = codegen_model.generate(**inputs_cg, max_length=150, num_return_sequences=1)\n",
        "    print(\"\\n=== CodeGen Continuation ===\\n\")\n",
        "    print(codegen_tokenizer.decode(outputs_cg[0], skip_special_tokens=True))\n",
        "\n",
        "    print(\"\\n=== Feedback Suggestions ===\")\n",
        "    for fb in detect_gaps(student_code):\n",
        "        print(\"-\", fb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUD5MxeUex2T",
        "outputId": "71160e29-abec-4738-bb86-010e96c98db3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Paste your Python code (type END to quit):\n",
            "def division(nums):\n",
            " a/b\n",
            "END\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Your Code ===\n",
            "def division(nums):\n",
            " a/b\n",
            "\n",
            "=== Embedding Shape (CodeBERT) ===\n",
            "torch.Size([1, 12, 768])\n",
            "\n",
            "=== CodeGen Continuation ===\n",
            "\n",
            "def division(nums):\n",
            " a/b = a/b\n",
            "    b/a = b/a\n",
            "    b//a = b/a\n",
            "    b/=a\n",
            "    b%a = b%a\n",
            "    b**a = b**a\n",
            "    b//=a\n",
            "    b%=a\n",
            "    b/=a\n",
            "    b%=a\n",
            "    b//=a\n",
            "    b%=a\n",
            "    b/=a\n",
            "    b%=a\n",
            "    b//=a\n",
            "    b%=a\n",
            "    b/=a\n",
            "    b%=a\n",
            "    b//=a\n",
            "    b%=a\n",
            "    b/=a\n",
            "    b%\n",
            "\n",
            "=== Feedback Suggestions ===\n",
            "-  No obvious conceptual gaps detected. Looks good!\n",
            "\n",
            "Paste your Python code (type END to quit):\n",
            "END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIcxR8SxfOkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}